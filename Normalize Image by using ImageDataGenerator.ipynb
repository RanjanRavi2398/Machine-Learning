{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (60000, 28, 28) (60000,)\n",
      "Test ((10000, 28, 28), (10000,))\n",
      "Train 0 255 33.318421449829934 78.56748998339798\n",
      "Test 0 255 33.791224489795916 79.17246322228644\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images,train_labels),(test_images,test_labels)=mnist.load_data()\n",
    "#summarize dataset shape\n",
    "print('Train',train_images.shape,train_labels.shape)\n",
    "print('Test',(test_images.shape,test_labels.shape))\n",
    "#summarize pixel values\n",
    "print('Train',train_images.min(),train_images.max(),train_images.mean(),train_images.std())\n",
    "print('Test',test_images.min(),test_images.max(),test_images.mean(),test_images.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train min=0.000,max=255.000\n",
      "Test min=0.000,max=255.000\n",
      "Batches train=938,test=157\n",
      "Batch shape=(64, 28, 28, 1),min=0.000,max=1.000\n",
      "WARNING:tensorflow:From /home/sastri/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/sastri/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 45s 48ms/step - loss: 0.1700 - accuracy: 0.9495\n",
      "Epoch 2/5\n",
      "211/938 [=====>........................] - ETA: 34s - loss: 0.0562 - accuracy: 0.9824"
     ]
    }
   ],
   "source": [
    "#example of using ImageDataGenerator to normalize images\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "(trainX,trainY),(testX,testY)=mnist.load_data()\n",
    "width,height,channels=trainX.shape[1],trainX.shape[2],1\n",
    "trainX=trainX.reshape((trainX.shape[0],width,height,channels))\n",
    "testX=testX.reshape((testX.shape[0],width,height,channels))\n",
    "#one hot encode target values\n",
    "trainY=to_categorical(trainY)\n",
    "testY=to_categorical(testY)\n",
    "print('Train min=%.3f,max=%.3f'%(trainX.min(),trainX.max()))\n",
    "print('Test min=%.3f,max=%.3f'%(testX.min(),testX.max()))\n",
    "#create generator\n",
    "datagen=ImageDataGenerator(rescale=1.0/255.0)\n",
    "#prepare an iterators to scale images\n",
    "train_iterator=datagen.flow(trainX,trainY,batch_size=64)\n",
    "test_iterator=datagen.flow(testX,testY,batch_size=64)\n",
    "print('Batches train=%d,test=%d'%(len(train_iterator),len(test_iterator)))\n",
    "#confirm the scaling works\n",
    "batchX,batchy=train_iterator.next()\n",
    "print('Batch shape=%s,min=%.3f,max=%.3f'%(batchX.shape,batchX.min(),batchX.max()))\n",
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(width,height,channels)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "#compile model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#fit model with generator\n",
    "model.fit_generator(train_iterator,steps_per_epoch=len(train_iterator),epochs=5)\n",
    "#evaluate model\n",
    "_,acc=model.evaluate_generator(test_iterator,steps=len(test_iterator),verbose=0)\n",
    "print('Test Accuracy:%.3f'%(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means train=33.318,test=33.791\n",
      "Data Generator mean:33.318\n",
      "(64, 28, 28, 1) -0.96931714\n",
      "(60000, 28, 28, 1) -1.9512918e-05\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "(trainX,trainy),(testX,testy)=mnist.load_data()\n",
    "width,height,channels=trainX.shape[1],trainX.shape[2],1\n",
    "trainX=trainX.reshape((trainX.shape[0],width,height,channels))\n",
    "testX=testX.reshape((testX.shape[0],width,height,channels))\n",
    "#report per-image mean\n",
    "print('Means train=%.3f,test=%.3f'%(trainX.mean(),testX.mean()))\n",
    "#create generator that centers pixels values\n",
    "datagen=ImageDataGenerator(featurewise_center=True)\n",
    "#calculate the mean on the training dataset\n",
    "datagen.fit(trainX)\n",
    "print('Data Generator mean:%.3f'%datagen.mean)\n",
    "#demonstrate effect on asingle batch of samples\n",
    "iterator=datagen.flow(trainX,trainy,batch_size=64)\n",
    "#get a batch\n",
    "batchX,batchy=iterator.next()\n",
    "#mean pixel value in the batch\n",
    "print(batchX.shape,batchX.mean())\n",
    "#demonstrate effect on entire training dataset\n",
    "iterator=datagen.flow(trainX,trainy,batch_size=len(trainX),shuffle=False)\n",
    "#get a batch\n",
    "batchX,batchy=iterator.next()\n",
    "#mean pixel value in the batch\n",
    "print(batchX.shape,batchX.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches train=938,test=157\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 58s 61ms/step - loss: 4.1653 - accuracy: 0.7173\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 58s 62ms/step - loss: 0.0634 - accuracy: 0.9815\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 59s 62ms/step - loss: 0.0457 - accuracy: 0.9860\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 59s 63ms/step - loss: 0.0377 - accuracy: 0.9886\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 59s 63ms/step - loss: 0.0317 - accuracy: 0.9901\n",
      "Test Accuracy:98.700\n"
     ]
    }
   ],
   "source": [
    "#example of using ImageDataGenerator to normalize images\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "(trainX,trainY),(testX,testY)=mnist.load_data()\n",
    "width,height,channels=trainX.shape[1],trainX.shape[2],1\n",
    "trainX=trainX.reshape((trainX.shape[0],width,height,channels))\n",
    "testX=testX.reshape((testX.shape[0],width,height,channels))\n",
    "#one hot encode target values\n",
    "trainY=to_categorical(trainY)\n",
    "testY=to_categorical(testY)\n",
    "#create generator\n",
    "datagen=ImageDataGenerator(featurewise_center=True)\n",
    "#calculate mean on training dataset\n",
    "datagen.fit(trainX)\n",
    "#prepare an iterators to scale images\n",
    "train_iterator=datagen.flow(trainX,trainY,batch_size=64)\n",
    "test_iterator=datagen.flow(testX,testY,batch_size=64)\n",
    "print('Batches train=%d,test=%d'%(len(train_iterator),len(test_iterator)))\n",
    "\n",
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(width,height,channels)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "#compile model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#fit model with generator\n",
    "model.fit_generator(train_iterator,steps_per_epoch=len(train_iterator),epochs=5)\n",
    "#evaluate model\n",
    "_,acc=model.evaluate_generator(test_iterator,steps=len(test_iterator),verbose=0)\n",
    "print('Test Accuracy:%.3f'%(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics train=33.318(78.567),test=33.791(79.172)\n",
      "Data Generator mean=33.318,std=78.567\n",
      "(64, 28, 28, 1) -0.00205506 0.9970326\n",
      "(60000, 28, 28, 1) -3.4560264e-07 0.9999998\n"
     ]
    }
   ],
   "source": [
    "(trainX,trainY),(testX,testY)=mnist.load_data()\n",
    "width,height,channels=trainX.shape[1],trainX.shape[2],1\n",
    "trainX=trainX.reshape((trainX.shape[0],width,height,channels))\n",
    "testX=testX.reshape((testX.shape[0],width,height,channels))\n",
    "#report pixel means and standard deviations\n",
    "print('Statistics train=%.3f(%.3f),test=%.3f(%.3f)'%(trainX.mean(),trainX.std(),testX.mean(),testX.std()))\n",
    "#create generator that centers pixel values\n",
    "datagen=ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True)\n",
    "#calculate the mean on the training dataset\n",
    "datagen.fit(trainX)\n",
    "print('Data Generator mean=%.3f,std=%.3f'%(datagen.mean,datagen.std))\n",
    "#effect on single batch of sample\n",
    "iterator=datagen.flow(trainX,trainy,batch_size=64)\n",
    "#get a batch\n",
    "batchX,batchy=iterator.next()\n",
    "#pixels stats in the batch\n",
    "print(batchX.shape,batchX.mean(),batchX.std())\n",
    "#effect on entire training dataset\n",
    "iterator=datagen.flow(trainX,trainy,batch_size=len(trainX),shuffle=False)\n",
    "#get a batch\n",
    "batchX,batchy=iterator.next()\n",
    "#pixel stats in the batch\n",
    "print(batchX.shape,batchX.mean(),batchX.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches train=938,test=157\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 57s 61ms/step - loss: 0.1603 - accuracy: 0.9511\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 63s 67ms/step - loss: 0.0493 - accuracy: 0.9853\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 59s 62ms/step - loss: 0.0333 - accuracy: 0.9894\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.0262 - accuracy: 0.9917\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 56s 60ms/step - loss: 0.0201 - accuracy: 0.9935\n",
      "Test Accuracy:99.070\n"
     ]
    }
   ],
   "source": [
    "#example of using ImageDataGenerator to normalize images\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "(trainX,trainY),(testX,testY)=mnist.load_data()\n",
    "width,height,channels=trainX.shape[1],trainX.shape[2],1\n",
    "trainX=trainX.reshape((trainX.shape[0],width,height,channels))\n",
    "testX=testX.reshape((testX.shape[0],width,height,channels))\n",
    "#one hot encode target values\n",
    "trainY=to_categorical(trainY)\n",
    "testY=to_categorical(testY)\n",
    "#create generator to standardize images\n",
    "datagen=ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True)\n",
    "#mean on training dataset\n",
    "datagen.fit(trainX)\n",
    "#prepare an iterators to scale images\n",
    "train_iterator=datagen.flow(trainX,trainY,batch_size=64)\n",
    "test_iterator=datagen.flow(testX,testY,batch_size=64)\n",
    "print('Batches train=%d,test=%d'%(len(train_iterator),len(test_iterator)))\n",
    "\n",
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(width,height,channels)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "#compile model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#fit model with generator\n",
    "model.fit_generator(train_iterator,steps_per_epoch=len(train_iterator),epochs=5)\n",
    "#evaluate model\n",
    "_,acc=model.evaluate_generator(test_iterator,steps=len(test_iterator),verbose=0)\n",
    "print('Test Accuracy:%.3f'%(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
